{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import random\n",
    "from csv import writer\n",
    "from sentence_transformers import SentenceTransformer, util, SentencesDataset, InputExample, losses, evaluation, models\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import sklearn\n",
    "from numba import cuda\n",
    "import math\n",
    "import json\n",
    "\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataframes\\\\final_wa_df.pickle', 'rb') as handle:\n",
    "    wa_df= pickle.load(handle)\n",
    "\n",
    "with open('dataframes\\\\final_stan_df.pickle', 'rb') as handle:\n",
    "    stan_df = pickle.load(handle)\n",
    "\n",
    "wa_content = wa_df.content.to_list()\n",
    "stan_content = stan_df.content.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RobBERT - mqa - wastan\n",
    "https://huggingface.co/jegormeister/robbert-v2-dutch-base-mqa-finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jegor sts wastan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models\\\\robbert-v2-dutch-base-mqa-wastan-finetuned'\n",
    "model = SentenceTransformer(model_save_path, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e0f654259e40c29883e8e0a099b067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169ac243a6e647b49c2490cb48f4cac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wa_embeddings = model.encode(wa_content, show_progress_bar=True)\n",
    "stan_embeddings = model.encode(stan_content, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings\\wa_mqa_wastan.pickle', 'wb') as handle:\n",
    "    pickle.dump(wa_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('embeddings\\stan_mqa_wastan.pickle', 'wb') as handle:\n",
    "    pickle.dump(stan_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('embeddings\\wa_mqa_wastan.pickle', 'rb') as handle:\n",
    "#     wa_embeddings = pickle.load(handle)\n",
    "\n",
    "# with open('embeddings\\stan_mqa_wastan.pickle', 'rb') as handle:\n",
    "#     stan_embeddings = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### robbert base wastan\n",
    "https://huggingface.co/pdelobelle/robbert-v2-dutch-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RobBERT - wastan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models\\\\robbert-v2-dutch-base-wastan-finetuned'\n",
    "model = SentenceTransformer(model_save_path, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1076bc0ea21c4e40b1be539cd862ccdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e89d3e18d1a4151becb11c047fb1638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wa_embeddings = model.encode(wa_content, show_progress_bar=True)\n",
    "stan_embeddings = model.encode(stan_content, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings\\wa_robbert_wastan.pickle', 'wb') as handle:\n",
    "    pickle.dump(wa_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('embeddings\\stan_robbert_wastan.pickle', 'wb') as handle:\n",
    "    pickle.dump(stan_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('embeddings\\wa_robbert_wastan.pickle', 'rb') as handle:\n",
    "#     wa_embeddings = pickle.load(handle)\n",
    "\n",
    "# with open('embeddings\\stan_robbert_wastan.pickle', 'rb') as handle:\n",
    "#     stan_embeddings = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_df = wa_df.drop(\"embeddings\", axis=1)\n",
    "stan_df = stan_df.drop(\"embeddings\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_df[\"embeddings\"] = wa_embeddings.tolist()\n",
    "stan_df[\"embeddings\"] = stan_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_df[\"date\"] = pd.to_datetime(wa_df['date'], format='%Y%m%d')\n",
    "stan_df[\"date\"] = pd.to_datetime(stan_df['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve top3 articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- voor elke rij in wa_df: filter standf obv relativedelta(weeks=-2)\n",
    "- convert content van limited df naar lijst\n",
    "- voor elke element in lijst: calculate cosine similarity\n",
    "- sla index op van top 3 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_indexes(list, searchcrit):\n",
    "    indexes = []\n",
    "    for idx, score in enumerate(list):\n",
    "        if score == searchcrit:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to retrieve the top 3 most similar articles within 2 weeks of the wablieft article\n",
    "def search_top3(index=int, wa_df=wa_df, stan_df=stan_df):\n",
    "    resultlist = []\n",
    "    row = wa_df.iloc[index]\n",
    "    limited_stan_df = stan_df[(stan_df[\"date\"] >= row.date + relativedelta(weeks=-2)) & (stan_df[\"date\"] <= row.date)]\n",
    "    for emb in limited_stan_df.embeddings.tolist():\n",
    "        resultlist.append((util.cos_sim(row.embeddings, emb)).item())\n",
    "\n",
    "    ## Get top 3\n",
    "    sortedlist = sorted(resultlist, reverse=True)\n",
    "    indexlist = []\n",
    "    for article in sortedlist[:3]:\n",
    "        idx = find_all_indexes(resultlist, article)\n",
    "        # idx = resultlist.index(article)\n",
    "        if len(idx) == 1:\n",
    "            stanfile = limited_stan_df.iloc[idx[0]]\n",
    "            indexlist.append(stanfile.filename)\n",
    "        else:\n",
    "            for index in idx:\n",
    "                stanfile = limited_stan_df.iloc[index]\n",
    "                indexlist.append(stanfile.filename)\n",
    "            break\n",
    "    # indexlist = [limited_stan_df.iloc[resultlist.index(article)].filename for article in sortedlist[:3]]\n",
    "    return sortedlist, indexlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return standaard article indexes based on the score\n",
    "sortedlist, indexlist= search_top3(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings\\wa_mqa_wastan.pickle', 'rb') as handle:\n",
    "    wa_embeddings = pickle.load(handle)\n",
    "\n",
    "with open('embeddings\\stan_mqa_wastan.pickle', 'rb') as handle:\n",
    "    stan_embeddings = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_df = wa_df.drop(\"embeddings\", axis=1)\n",
    "stan_df = stan_df.drop(\"embeddings\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_df[\"embeddings\"] = wa_embeddings.tolist()\n",
    "stan_df[\"embeddings\"] = stan_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simDict_mqa_WaStan = {wa_df.iloc[i].filename: {'Standaard': search_top3(i)[1], 'Score': search_top3(i)[0][:3]} for i in range(0, len(wa_content))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comparable_corpora\\simDict_mqa_WaStan_definitive.json', 'w') as fp:\n",
    "    json.dump(simDict_mqa_WaStan, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_df = wa_df.drop(\"embeddings\", axis=1)\n",
    "stan_df = stan_df.drop(\"embeddings\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings\\wa_robbert_wastan.pickle', 'rb') as handle:\n",
    "    wa_embeddings = pickle.load(handle)\n",
    "\n",
    "with open('embeddings\\stan_robbert_wastan.pickle', 'rb') as handle:\n",
    "    stan_embeddings = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_df[\"embeddings\"] = wa_embeddings.tolist()\n",
    "stan_df[\"embeddings\"] = stan_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simDictRobBERT_WaStan = {wa_df.iloc[i].filename: {'Standaard': search_top3(i)[1], 'Score': search_top3(i)[0][:3]} for i in range(0, len(wa_content))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comparable_corpora\\simDict_RobBERT_WaStan.json', 'w') as fp:\n",
    "    json.dump(simDictRobBERT_WaStan, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllSimScores(dict):\n",
    "    simScoreList = []\n",
    "    for wa, subdict in dict.items():\n",
    "        for i in range(0, len(subdict.get(\"Score\"))):\n",
    "            simScoreList.append(subdict.get(\"Score\")[i])\n",
    "    \n",
    "    return simScoreList\n",
    "\n",
    "def getTop1SimScores(dict):\n",
    "    simScoreList = []\n",
    "    for wa, subdict in dict.items():\n",
    "        try:\n",
    "            simScoreList.append(subdict.get(\"Score\")[0])\n",
    "        except IndexError:\n",
    "            continue\n",
    "    \n",
    "    return simScoreList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in previously saved similarity dictionary\n",
    "with open('comparable_corpora\\simDict_RobBERT_WaStan.json') as json_file:\n",
    "    robb_wastan = json.load(json_file)\n",
    "\n",
    "# Load in previously saved similarity dictionary\n",
    "with open('comparable_corpora\\simDict_mqa_WaStan.json') as json_file:\n",
    "    mqa_wastan = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_robbwastan = getTop1SimScores(robb_wastan)\n",
    "\n",
    "with open('comparable_corpora\\similarity_scores\\\\top1SimScoreListRobBERTWaStan.pickle', 'wb') as handle:\n",
    "    pickle.dump(top1_robbwastan, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "top1_mqawastan = getTop1SimScores(mqa_wastan)\n",
    "\n",
    "with open('comparable_corpora\\similarity_scores\\\\top1SimScoreListmqaWaStan.pickle', 'wb') as handle:\n",
    "    pickle.dump(top1_mqawastan, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def getSimfromDict(dict, amount=int):\n",
    "    walist = []\n",
    "    stanlist = []\n",
    "    scorelist = []\n",
    "    for wa, value in itertools.islice(dict.items(), amount):\n",
    "        walist.append(wa_df.loc[wa_df['filename']==wa][\"content\"].tolist()[0])\n",
    "        stanlist.append(value.get(\"Standaard\"))\n",
    "        scorelist.append(value.get(\"Score\"))\n",
    "    \n",
    "    return walist, stanlist, scorelist\n",
    "        # for stan, score in value.value:\n",
    "        #     for i in range(0, len(stan.values())):\n",
    "        #         print(\"Standaard article: \" + stan_df.loc[stan_df[\"filename\" == stan.values()[i]]]+\"\\n\"+\"Score: \"+score.values()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSimilarArticles(wablieftContent, stanFileNames, Scores):\n",
    "    for i in range(0, len(stanFileNames)):\n",
    "        print(\"\\n\\n\"+\"Wablieft article: \"+wablieftContent[i]+\"\\n\")\n",
    "        for j in range(0, 3):\n",
    "            try:\n",
    "                stanContent = stan_df.loc[stan_df[\"filename\"] == stanFileNames[i][j]]['content'].tolist()\n",
    "                score = Scores[i][j]\n",
    "            except IndexError:\n",
    "                break\n",
    "\n",
    "            print(\"Standaard article: \"+stanContent[0])\n",
    "            print(\"Score: \"+ str(score)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wab, stan, scores = getSimfromDict(dict=simDict, amount=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printSimilarArticles(wab, stan, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary of top 1 similar article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_top1(index=int, wa_df=wa_df, stan_df=stan_df):\n",
    "    resultlist = []\n",
    "    row = wa_df.iloc[index]\n",
    "    limited_stan_df = stan_df[(stan_df[\"date\"] >= row.date + relativedelta(weeks=-2)) & (stan_df[\"date\"] <= row.date)]\n",
    "    for emb in limited_stan_df.embeddings.tolist():\n",
    "        resultlist.append((util.cos_sim(row.embeddings, emb)).item())\n",
    "\n",
    "    ## Get top 3\n",
    "    sortedlist = sorted(resultlist, reverse=True)\n",
    "    indexlist = []\n",
    "    for article in sortedlist[:1]:\n",
    "        idx = find_all_indexes(resultlist, article)\n",
    "        # idx = resultlist.index(article)\n",
    "        if len(idx) == 1:\n",
    "            stanfile = limited_stan_df.iloc[idx[0]]\n",
    "            indexlist.append(stanfile.filename)\n",
    "        else:\n",
    "            for index in idx:\n",
    "                stanfile = limited_stan_df.iloc[index]\n",
    "                indexlist.append(stanfile.filename)\n",
    "            break\n",
    "    # indexlist = [limited_stan_df.iloc[resultlist.index(article)].filename for article in sortedlist[:3]]\n",
    "    return sortedlist, indexlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholding to construct comparable corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = 0.642\n",
    "simDictTop1 = {}\n",
    "for i in range(0, len(wa_content)):\n",
    "    sim_score, stan_filename = search_top1(i)\n",
    "    try:\n",
    "\n",
    "\n",
    "        if float(sim_score[0]) >= score_threshold:\n",
    "            simDictTop1[wa_df.iloc[i].filename] = {'Standaard': stan_filename[0], 'Score': sim_score[0]}\n",
    "        else:\n",
    "            continue\n",
    "    except IndexError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('similarityDictionaryTop1.json', 'w') as fp:\n",
    "    json.dump(simDictTop1, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comparable_corpora\\simDict_LogRegClassified.json') as json_file:\n",
    "    simDict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimfromDict(dict):\n",
    "    walist = []\n",
    "    stanlist = []\n",
    "    scorelist = []\n",
    "    for wa, value in dict.items():\n",
    "        walist.append(wa_df.loc[wa_df['filename']==wa][\"content\"].tolist()[0])\n",
    "        stanlist.append(value.get(\"Standaard\"))\n",
    "        scorelist.append(value.get(\"Score\"))\n",
    "    \n",
    "    return walist, stanlist, scorelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSimilarArticles(wablieftContent, stanFileNames, Scores):\n",
    "    for i in range(0, len(stanFileNames)):\n",
    "        print(\"\\n\\n\"+\"Wablieft article: \"+wablieftContent[i]+\"\\n\")\n",
    "        try:\n",
    "            stanContent = stan_df.loc[stan_df[\"filename\"] == stanFileNames[i]]['content'].tolist()\n",
    "            score = Scores[i]\n",
    "        except IndexError:\n",
    "            break\n",
    "\n",
    "        print(\"Standaard article: \"+stanContent[0])\n",
    "        print(\"Score: \"+ str(score)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wab, stan, scores = getSimfromDict(dict=simDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printSimilarArticles(wab, stan, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training set with scored articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### scorelists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchesList = [0.7697,\n",
    "        0.72141486,\n",
    "        0.71388,\n",
    "        0.788607,\n",
    "        0.836498,\n",
    "        0.704664,\n",
    "        0.7805206,\n",
    "        0.80987,\n",
    "        0.797313,\n",
    "        0.743338346,\n",
    "        0.799838,\n",
    "        0.781242,\n",
    "        0.673715,\n",
    "        0.7851778864,\n",
    "        0.680668,\n",
    "        0.8285657,\n",
    "        0.77680337,\n",
    "        0.89255422,\n",
    "        0.710689,\n",
    "        0.792078137,\n",
    "        0.75573337,\n",
    "        0.8639686,\n",
    "        0.923899,\n",
    "        0.8299018,\n",
    "        0.818773388,\n",
    "        0.774552166,\n",
    "        0.791702,\n",
    "        0.6543264,\n",
    "        0.788223028,\n",
    "        0.7355657,\n",
    "        0.67106187,\n",
    "        0.580847,\n",
    "        0.627487,\n",
    "        0.66209,\n",
    "        0.681355,\n",
    "        0.768626,\n",
    "        0.733748,\n",
    "        0.69154,\n",
    "        0.51817,\n",
    "        0.681477,\n",
    "        0.78126,\n",
    "        0.7633886,\n",
    "        0.8638988,\n",
    "        0.5258505,\n",
    "        0.783164,\n",
    "        0.777009,\n",
    "        0.64473,\n",
    "        0.729588,\n",
    "        0.763598,\n",
    "        0.8209926,\n",
    "        0.8132002,\n",
    "        0.7953649,\n",
    "        0.776327,\n",
    "        0.755874,\n",
    "        0.756482899,\n",
    "        0.75797,\n",
    "        0.7536767,\n",
    "        0.6356,\n",
    "        0.708218,\n",
    "        0.76766467,\n",
    "        0.7696149,\n",
    "        0.61336,\n",
    "        0.6577181,\n",
    "        0.7659018,\n",
    "        0.759663,\n",
    "        0.76228386,\n",
    "        0.85247099,\n",
    "        0.73827588,\n",
    "        0.4924735,\n",
    "        0.7233466,\n",
    "        0.76480269,\n",
    "        0.63647,\n",
    "        0.72138,\n",
    "        0.8175677,\n",
    "        0.70753,\n",
    "        0.737872,\n",
    "        0.753278,\n",
    "        0.838064,\n",
    "        0.726966,\n",
    "        0.8079567,\n",
    "        0.653346,\n",
    "        0.74183446,\n",
    "        0.81097239,\n",
    "        0.689377367,\n",
    "        0.62185,\n",
    "        0.75594,\n",
    "        0.7558307,\n",
    "        0.7798176,\n",
    "        0.847305,\n",
    "        0.754778,\n",
    "        0.642159,\n",
    "        0.74452215,\n",
    "        0.7798978,\n",
    "        0.75354,\n",
    "        0.5777378,\n",
    "        0.799755,\n",
    "        0.73424,\n",
    "        0.5977584,\n",
    "        0.686517,\n",
    "        0.6422056,\n",
    "        0.6759755,\n",
    "        0.695020914,\n",
    "        0.853763,\n",
    "        0.82201665,\n",
    "        0.69139,\n",
    "        0.631638,\n",
    "        0.76909,\n",
    "        0.847588956,\n",
    "        0.79919,\n",
    "        0.78601,\n",
    "        0.7322576,\n",
    "        0.7635,\n",
    "        0.77563,\n",
    "        0.72278499,\n",
    "        0.811708,\n",
    "        0.66525,\n",
    "        0.6677179,\n",
    "        0.78369,\n",
    "        0.6500568,\n",
    "        0.76673,\n",
    "        0.718989,\n",
    "        0.73766,\n",
    "        0.77780485,\n",
    "        0.751827,\n",
    "        0.77792,\n",
    "        0.5125471,\n",
    "        0.7146214,\n",
    "        0.712471485,\n",
    "        0.64337754249,\n",
    "        0.666738927,\n",
    "        0.6788367629,\n",
    "        0.6716255,\n",
    "        0.843695998,\n",
    "        0.674108445644,\n",
    "        0.7829052805,\n",
    "        0.70365959405899,\n",
    "        0.77655506,\n",
    "        0.6633684635,\n",
    "        0.8291893601,\n",
    "        0.7387883067,\n",
    "        0.73019278049,\n",
    "        0.6969285607,\n",
    "        0.714788675,\n",
    "        0.760915637,\n",
    "        0.8273297548,\n",
    "        0.923899471759,\n",
    "        0.9047259688,\n",
    "        0.9037084579467,\n",
    "        0.5706487298,\n",
    "        0.77131378,\n",
    "        0.818009138,\n",
    "        0.7564840316,\n",
    "        0.7415358424,\n",
    "        0.83821976,\n",
    "        0.7958508729934,\n",
    "        0.816393852233,\n",
    "        0.855634,\n",
    "        0.764023065567,\n",
    "        0.6651859879,\n",
    "        0.639792382717,\n",
    "        0.7571749687,\n",
    "        0.82533246,\n",
    "        0.834297776,\n",
    "        0.833146095,\n",
    "        0.83930498361,\n",
    "        0.61638921499,\n",
    "        0.543234169,\n",
    "        0.7669585347,\n",
    "        0.6891207098,\n",
    "        0.63000345,\n",
    "        0.752358198,\n",
    "        0.78967285,\n",
    "        0.760514676,\n",
    "        0.6784633994,\n",
    "        0.7990390658,\n",
    "        0.860850214958,\n",
    "        0.689050734,\n",
    "        0.711645185947,\n",
    "        0.746158,\n",
    "        0.74563032,\n",
    "        0.7669916749,\n",
    "        0.7235053777,\n",
    "        0.8123298,\n",
    "        0.6792410016,\n",
    "        0.701078534,\n",
    "        0.71442246437,\n",
    "        0.722155749,\n",
    "        0.80628609,\n",
    "        0.7795466184616,\n",
    "        0.739085,\n",
    "        0.78737384,\n",
    "        0.823471367,\n",
    "        0.637516,\n",
    "        0.7135028,\n",
    "        0.64341038,\n",
    "        0.6608159,\n",
    "        0.79101634,\n",
    "        0.60918426,\n",
    "        0.6051189899,\n",
    "        0.72729367,\n",
    "        0.89086,\n",
    "        0.6616236,\n",
    "        0.71711957,\n",
    "        0.69035869,\n",
    "        0.6787018,\n",
    "        0.6538558,\n",
    "        0.74488943815,\n",
    "        0.791976,\n",
    "        0.82162,\n",
    "        0.7984265089,\n",
    "        0.76979,\n",
    "        0.6847710609,\n",
    "        0.8136815,\n",
    "        0.6635019,\n",
    "        0.87014955,\n",
    "        0.820418238,\n",
    "        0.74413615,\n",
    "        0.69744706,\n",
    "        0.7076369,\n",
    "        0.704141259,\n",
    "        0.772098,\n",
    "        0.7256688,\n",
    "        0.74525088,\n",
    "        0.771788299,\n",
    "        0.88479,\n",
    "        0.78804278,\n",
    "        0.703075,\n",
    "        0.581823587,\n",
    "        0.7161303,\n",
    "        0.72783309,\n",
    "        0.787395,\n",
    "        0.714924,\n",
    "        0.7885076999,\n",
    "        0.7974855899,\n",
    "        0.82318055,\n",
    "        0.732838809,\n",
    "        0.66058075,\n",
    "        0.719847,\n",
    "        0.809242546,\n",
    "        0.7810799,\n",
    "        0.746488,\n",
    "        0.68827325,\n",
    "        0.62747842,\n",
    "        0.70261967,\n",
    "        0.8243128,\n",
    "        0.7264975309,\n",
    "        0.7546389,\n",
    "        0.7904949,\n",
    "        0.73430216,\n",
    "        0.739148557,\n",
    "        0.64654779,\n",
    "        0.81631809,\n",
    "        0.7605623,\n",
    "        0.4436697,\n",
    "        0.7363989,\n",
    "        0.840628445,\n",
    "        0.7958248,\n",
    "        0.8284159,\n",
    "        0.81944477,\n",
    "        0.7998687,\n",
    "        0.7483889,\n",
    "        0.76568597,\n",
    "        0.778772,\n",
    "        0.77987897,\n",
    "        0.773603618,\n",
    "        0.800198,\n",
    "        0.73052,\n",
    "        0.7266547,\n",
    "        0.727787077,\n",
    "        0.6135877,\n",
    "        0.6108038,\n",
    "        0.710565,\n",
    "        0.6744478\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "noMatchesList = [\n",
    "    0.5535407,\n",
    "    0.6986519,\n",
    "    0.51107543,\n",
    "    0.4589526,\n",
    "    0.5063756,\n",
    "    0.52886277,\n",
    "    0.5447489,\n",
    "    0.55582004,\n",
    "    0.57022494,\n",
    "    0.552105307579,\n",
    "    0.6082630157,\n",
    "    0.57582497,\n",
    "    0.63724285,\n",
    "    0.61024689,\n",
    "    0.5978436,\n",
    "    0.595395088,\n",
    "    0.5180177,\n",
    "    0.622035026,\n",
    "    0.689134597,\n",
    "    0.48909914449,\n",
    "    0.498851418,\n",
    "    0.44220787,\n",
    "    0.512252509,\n",
    "    0.548665285,\n",
    "    0.5386719,\n",
    "    0.50775814056,\n",
    "    0.4760343,\n",
    "    0.569921,\n",
    "    0.4769304,\n",
    "    0.571814239,\n",
    "    0.5141970515,\n",
    "    0.55523240566,\n",
    "    0.6670523881,\n",
    "    0.65486276,\n",
    "    0.642258465,\n",
    "    0.5293843746,\n",
    "    0.622388899,\n",
    "    0.59334117174,\n",
    "    0.6066381335,\n",
    "    0.52446991205,\n",
    "    0.660279095,\n",
    "    0.61309307,\n",
    "    0.61719208955,\n",
    "    0.509504199,\n",
    "    0.53461307,\n",
    "    0.55632734,\n",
    "    0.5305280089378,\n",
    "    0.5029930472,\n",
    "    0.60603237,\n",
    "    0.49210578,\n",
    "    0.635853469,\n",
    "    0.6405651569,\n",
    "    0.678285896778,\n",
    "    0.513371527,\n",
    "    0.71126574,\n",
    "    0.455496877,\n",
    "    0.67995160818,\n",
    "    0.691637158,\n",
    "    0.637583673,\n",
    "    0.63278347,\n",
    "    0.4872620998,\n",
    "    0.668940067,\n",
    "    0.61449253559,\n",
    "    0.554829,\n",
    "    0.4880725,\n",
    "    0.54832077026,\n",
    "    0.5618026256,\n",
    "    0.56353968,\n",
    "    0.489055693149,\n",
    "    0.46197,\n",
    "    0.55689138,\n",
    "    0.640002429,\n",
    "    0.54211628,\n",
    "    0.557211399,\n",
    "    0.595259,\n",
    "    0.6195359,\n",
    "    0.5236569,\n",
    "    0.664387,\n",
    "    0.6819516,\n",
    "    0.503838,\n",
    "    0.576270997,\n",
    "    0.62811075,\n",
    "    0.604570508,\n",
    "    0.6187288,\n",
    "    0.654753,\n",
    "    0.59569638967,\n",
    "    0.5765741467,\n",
    "    0.65639215,\n",
    "    0.560441255,\n",
    "    0.52692282,\n",
    "    0.62480497,\n",
    "    0.5717596,\n",
    "    0.4443662,\n",
    "    0.5964726,\n",
    "    0.63212949,\n",
    "    0.6097509,\n",
    "    0.61967355,\n",
    "    0.68474,\n",
    "    0.73098,\n",
    "    0.469717,\n",
    "    0.6137657,\n",
    "    0.61052447557,\n",
    "    0.4984967,\n",
    "    0.6565629,\n",
    "    0.59753525257,\n",
    "    0.5660267,\n",
    "    0.6557744,\n",
    "    0.56982338,\n",
    "    0.62308949,\n",
    "    0.545513,\n",
    "    0.60677,\n",
    "    0.715595,\n",
    "    0.7052625,\n",
    "    0.61761957,\n",
    "    0.64363306,\n",
    "    0.6009945,\n",
    "    0.592138707,\n",
    "    0.61603069,\n",
    "    0.598185658,\n",
    "    0.5933338,\n",
    "    0.6277466,\n",
    "    0.5623755,\n",
    "    0.6203489,\n",
    "    0.5040397,\n",
    "    0.73360979,\n",
    "    0.7952144,\n",
    "    0.45291349,\n",
    "    0.41730788,\n",
    "    0.54704487,\n",
    "    0.4835606,\n",
    "    0.5867008,\n",
    "    0.49841472,\n",
    "    0.556829,\n",
    "    0.74117487,\n",
    "    0.444108039,\n",
    "    0.488289,\n",
    "    0.57693058,\n",
    "    0.528937,\n",
    "    0.520601\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dataframe with previously scored articles to explore and evaluate classifier and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in previously saved similarity dictionary\n",
    "with open('comparable_corpora\\simDict_mqa_WaStan.json') as json_file:\n",
    "    simDict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainingSet(dict, wa_df=wa_df, stan_df=stan_df, scoreList=list, scoreRated=int):\n",
    "    df = pd.DataFrame()\n",
    "    waClist = []\n",
    "    waTlist = []\n",
    "    stanClist = []\n",
    "    stanTlist = []\n",
    "    scorelist = []\n",
    "    matchList = []\n",
    "    bMatch = False\n",
    "    for score in scoreList:\n",
    "        score = str(score)\n",
    "        for wa, value in dict.items():\n",
    "            for i in range(0, 3):\n",
    "                try:\n",
    "                    if str(value.get(\"Score\")[i]).__contains__(score):\n",
    "                        waClist.append(wa_df.loc[wa_df[\"filename\"] == wa][\"content\"].tolist()[0])\n",
    "                        waTlist.append(wa_df.loc[wa_df[\"filename\"] == wa][\"title\"].tolist()[0])\n",
    "                        stanClist.append(stan_df.loc[stan_df[\"filename\"] == value.get(\"Standaard\")[i]][\"content\"].tolist()[0])\n",
    "                        stanTlist.append(stan_df.loc[stan_df[\"filename\"] == value.get(\"Standaard\")[i]][\"title\"].tolist()[0])\n",
    "                        scorelist.append(float(score))\n",
    "                        matchList.append(scoreRated)\n",
    "                        bMatch = True\n",
    "                        break\n",
    "                except IndexError:\n",
    "                    break\n",
    "            if bMatch==True:\n",
    "                bMatch = False\n",
    "                break\n",
    "    \n",
    "    df[\"WaTitle\"] = waTlist\n",
    "    df[\"WaContent\"] = waClist\n",
    "    df[\"StanTitle\"] = stanTlist\n",
    "    df[\"StanContent\"] = stanClist\n",
    "    df[\"Score\"] = scorelist\n",
    "    df[\"Match\"] = matchList\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchDf = createTrainingSet(scoreList = matchesList, scoreRated=1)\n",
    "noMatchDf = createTrainingSet(scoreList=noMatchesList, scoreRated=0)\n",
    "evaluationDf = matchDf.append(noMatchDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WaTitle</th>\n",
       "      <th>WaContent</th>\n",
       "      <th>StanTitle</th>\n",
       "      <th>StanContent</th>\n",
       "      <th>Score</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minder kinderen geboren</td>\n",
       "      <td>Minder kinderen geboren In Vlaamse ziekenhuize...</td>\n",
       "      <td>66.822</td>\n",
       "      <td>Geboortes 66.822 Het afgelopen jaar werden iet...</td>\n",
       "      <td>0.769700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vlaams medicijn tegen tbc</td>\n",
       "      <td>Vlaams medicijn tegen tbc Onderzoekers van het...</td>\n",
       "      <td>Vlaams medicijn brengt hoop voor stervenden me...</td>\n",
       "      <td>Ook Artsen zonder Grenzen vraagt al lang om he...</td>\n",
       "      <td>0.721415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vlaams medicijn tegen tbc</td>\n",
       "      <td>Vlaams medicijn tegen tbc Onderzoekers van het...</td>\n",
       "      <td>No title</td>\n",
       "      <td>Vlaams medicijn brengt hoop in strijd tegen tbc</td>\n",
       "      <td>0.713880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Directrice verdacht van spieken</td>\n",
       "      <td>Directrice verdacht van spieken De directrice ...</td>\n",
       "      <td>Directrice laat eigen kinderen examenvragen in...</td>\n",
       "      <td>Directrice laat eigen kinderen examenvragen in...</td>\n",
       "      <td>0.788607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noémie is Miss België</td>\n",
       "      <td>Noémie is Miss België Noémie Happart is de moo...</td>\n",
       "      <td>Noémie Happart Miss België 2013</td>\n",
       "      <td>Noémie Happart Miss België 2013 Noémie Happart...</td>\n",
       "      <td>0.836498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Niet te scheiden</td>\n",
       "      <td>Niet te scheiden De Amerikaanse honden Hoshi e...</td>\n",
       "      <td>No title</td>\n",
       "      <td>De kleine parade Selena Gomez stopt met optred...</td>\n",
       "      <td>0.444108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Hoog en hoger</td>\n",
       "      <td>Hoog en hoger Meer dan 12 euro voor een ritje ...</td>\n",
       "      <td>No title</td>\n",
       "      <td>De kleine parade Het huis van Freddie Als hij ...</td>\n",
       "      <td>0.488289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Ruim het op!</td>\n",
       "      <td>Ruim het op! Vorige week zat ik in de klas van...</td>\n",
       "      <td>Warenhuisketen Colruyt bindt strijd aan met zw...</td>\n",
       "      <td>' Wanneer we de strijd willen aanbinden met zw...</td>\n",
       "      <td>0.576931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>China ontruimt kloosters</td>\n",
       "      <td>China ontruimt kloosters De overheid in China ...</td>\n",
       "      <td>Ook slachthuizen slachten liever niet onverdoofd</td>\n",
       "      <td>' De ene imam is nog strenger dan de andere en...</td>\n",
       "      <td>0.528937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Russen redden Palmyra</td>\n",
       "      <td>Russen redden Palmyra Het leger van Rusland st...</td>\n",
       "      <td>Turkije maakt grens IS- (en Koerden-)vrij</td>\n",
       "      <td>Turkije maakt grens IS - ( en Koerden-)vrij Ve...</td>\n",
       "      <td>0.520601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             WaTitle  \\\n",
       "0            Minder kinderen geboren   \n",
       "1          Vlaams medicijn tegen tbc   \n",
       "2          Vlaams medicijn tegen tbc   \n",
       "3    Directrice verdacht van spieken   \n",
       "4              Noémie is Miss België   \n",
       "..                               ...   \n",
       "131                 Niet te scheiden   \n",
       "132                    Hoog en hoger   \n",
       "133                     Ruim het op!   \n",
       "134         China ontruimt kloosters   \n",
       "135            Russen redden Palmyra   \n",
       "\n",
       "                                             WaContent  \\\n",
       "0    Minder kinderen geboren In Vlaamse ziekenhuize...   \n",
       "1    Vlaams medicijn tegen tbc Onderzoekers van het...   \n",
       "2    Vlaams medicijn tegen tbc Onderzoekers van het...   \n",
       "3    Directrice verdacht van spieken De directrice ...   \n",
       "4    Noémie is Miss België Noémie Happart is de moo...   \n",
       "..                                                 ...   \n",
       "131  Niet te scheiden De Amerikaanse honden Hoshi e...   \n",
       "132  Hoog en hoger Meer dan 12 euro voor een ritje ...   \n",
       "133  Ruim het op! Vorige week zat ik in de klas van...   \n",
       "134  China ontruimt kloosters De overheid in China ...   \n",
       "135  Russen redden Palmyra Het leger van Rusland st...   \n",
       "\n",
       "                                             StanTitle  \\\n",
       "0                                               66.822   \n",
       "1    Vlaams medicijn brengt hoop voor stervenden me...   \n",
       "2                                             No title   \n",
       "3    Directrice laat eigen kinderen examenvragen in...   \n",
       "4                      Noémie Happart Miss België 2013   \n",
       "..                                                 ...   \n",
       "131                                           No title   \n",
       "132                                           No title   \n",
       "133  Warenhuisketen Colruyt bindt strijd aan met zw...   \n",
       "134   Ook slachthuizen slachten liever niet onverdoofd   \n",
       "135          Turkije maakt grens IS- (en Koerden-)vrij   \n",
       "\n",
       "                                           StanContent     Score  Match  \n",
       "0    Geboortes 66.822 Het afgelopen jaar werden iet...  0.769700      1  \n",
       "1    Ook Artsen zonder Grenzen vraagt al lang om he...  0.721415      1  \n",
       "2     Vlaams medicijn brengt hoop in strijd tegen tbc   0.713880      1  \n",
       "3    Directrice laat eigen kinderen examenvragen in...  0.788607      1  \n",
       "4    Noémie Happart Miss België 2013 Noémie Happart...  0.836498      1  \n",
       "..                                                 ...       ...    ...  \n",
       "131  De kleine parade Selena Gomez stopt met optred...  0.444108      0  \n",
       "132  De kleine parade Het huis van Freddie Als hij ...  0.488289      0  \n",
       "133  ' Wanneer we de strijd willen aanbinden met zw...  0.576931      0  \n",
       "134  ' De ene imam is nog strenger dan de andere en...  0.528937      0  \n",
       "135  Turkije maakt grens IS - ( en Koerden-)vrij Ve...  0.520601      0  \n",
       "\n",
       "[407 rows x 6 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluationDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataframes\\manualRatedDf.pickle', 'wb') as handle:\n",
    "    pickle.dump(evaluationDf, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('dataframes\\manualRatedDf.pickle', 'rb') as handle:\n",
    "    evaluationDf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8744"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wa_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kies mee een naam voor babypanda In dierenpark Pairi Daiza wordt de babypanda drie maanden oud. Dan krijgt hij zijn echte naam. Nu heet hij enkel P. Een panda is een Chinees dier. Dus krijgt P een Chinese naam. Mensen kunnen mee kiezen uit vijf namen. Dat zijn Tian Bao (Schat van de Hemel), Xing Hao (Goede Ster), Ou Xing (Ster van Europa), Hua Li (China en België) en An Tuan (Verenigde Vrede). De pandaploeg van Pairi Daiza kiest uit de beste drie namen de echte naam. Stem op je favoriet op  www.pairidaiza.eu.  '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa_df.loc[wa_df[\"filename\"] == 'wa1110bik1.txt'][\"content\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"NATUUR Panda's niet meer met uitsterven bedreigd Het zal niet alleen aan het Belgische geboortecijfer liggen , maar op de jongste ' Rode Lijst ' is de reuzenpanda opgeschoven van ' bedreigd ' naar ' kwetsbaar '. Met de gorilla gaat het dan weer van kwaad naar erger . Van onze redacteur Pieter Van Dooren Met hun eenzijdige dieet van ' bamboe en niks dan bamboe ' hadden de reuzenpanda's zich in een kwetsbare situatie gemanoeuvreerd . De Chinezen proberen al decennia om hun aantallen op te voeren met intensieve kweek\\xadprogramma's , maar de panda's werkten niet echt mee . Ook al hebben Xing Hui en Hao Hao in juni in Pairi Daiza hun plicht gedaan en de wereld verrijkt met \\xadBaby P , die een week geleden zijn eerste stapjes zette . Belangrijker was de Chinese bescherming van de bamboebossen - alleen in die bossen komt de \\xadreuzenpanda nog in het wild voor . Het jongste decennium gingen de aantallen met 17 procent vooruit , zegt het Wereldnatuurfonds ( dat een panda in zijn logo voert ). Genoeg voor de Internationale Unie voor de Conservatie van de Natuur ( IUCN ) om de reuzenpanda's een categorie hoger te plaatsen op haar nieuwe ' Rode Lijst '. Ze verhuizen van ' bedreigd ' naar ' kwetsbaar '. In elk geval voorlopig , want de klimaatopwarming zou de Chinese inspanningen voor de natuur wel eens teniet kunnen doen , zo waarschuwt de IUCN . China mag zich op de borst kloppen , want ook het aantal Tibetaanse anti\\xadlopen is toegenomen . Gorilla Erger is het gesteld met de gorilla's . Ook de oostelijke gorilla , die de jongste twintig jaar met zeventig procent achteruitging , staat nu te boek als ' kritiek ', één hokje \\xadboven ' uitgestorven '. De westelijke gorilla zat daar al langer , net als de orang-oetan . Chimpansees en bonobo's zijn ' bedreigd '. De Homo \\xadsapiens , die eerder de andere soorten van het geslacht Homo al van het toneel duwde , is blijkbaar hetzelfde aan het doen met zijn andere nauwe verwanten , de mensapen . De oostelijke gorilla's komen nog voor in een paar stukjes regenwoud in Oeganda , Rwanda en Congo , maar burgeroorlogen , stropers en armoede zijn hen \\xadfataal aan het worden . Dezelfde soort oorzaken die bijvoorbeeld ook de steppezebra's in veertien jaar tijd met een kwart omlaag duwden . De IUCN volgt 82.954 soorten planten en dieren . Daarvan zijn er 23.928 met uitsterven bedreigd , en voor 5.107 soorten kan ieder moment het laatste zijn . Vooral soorten planten , amfibieën , schelpdieren en vissen staan op het randje van uitsterven . Bio\\xadlogen spreken dan ook van de \\xad'zesde massa-uitsterving ' in de wereldgeschiedenis . De vorige keer was 66 miljoen jaar geleden , toen de dinosaurussen en zo'n driekwart van de andere soorten uitstierven door een inslaande reuzenmeteoriet . \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stan_df.loc[stan_df[\"filename\"] == '08857008-7367-11e6-ba51-194230acc9a8_DB.000001.xml'][\"content\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wa_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26296\\1518619386.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwa_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwa_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"filename\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'wa936spk4.txt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wa_df' is not defined"
     ]
    }
   ],
   "source": [
    "embedding = wa_df.loc[wa_df[\"filename\"] == 'wa935bui2.txt'][\"embeddings\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_test = []\n",
    "for stemb in stan_df.embeddings.tolist():\n",
    "    dif = util.cos_sim(embedding, stemb)\n",
    "    emb_test.append(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedemb = sorted(emb_test, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexlist = []\n",
    "for ele in sortedemb[:10]:\n",
    "    idx = emb_test.index(ele)\n",
    "    indexlist.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Heb jij ze wel alle vijf? De tijd van armoede in ons land is niet voorbij. Vandaag kennen heel wat mensen nog altijd armoede en uitsluiting. Wat betekent dat voor jongeren? Educatief Theater Antwerpen maakte er een toneelstuk over.   Schrijvers Marc Hendrickx en Dirk Dobbeleers duiken in de wereld van jongeren. School, tv, talentenjachten, liefde\\x85  zijn belangrijk in die wereld. Hoofdrollen zijn er voor de meisjes Chelsea, Phaedra en Yasim. Maken ze hun dromen waar? Gezin en geld spelen daarbij een grote rol.  Educatief Theater Antwerpen toont 'Heb je ze wel alle vijf?' dit jaar nog 12 keer in Vlaanderen. Nadien krijgt het stuk een kans in scholen en verenigingen. Die kunnen het stuk aankopen voor een zaal tot 200 kijkers. Meer info op 03 226 42 00.  Praktisch Het toneelstuk 'Heb je ze wel alle vijf?' kan je tot 25 november gaan bekijken in Leuven, Sint-Truiden, Roeselare, Gent, Heist-op-den-Berg, Halle, Tongeren, Mechelen, Kortrijk, Hasselt, Deurne en Tienen. Meer info op www.etaproducties.be.  \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa_df.loc[wa_df[\"filename\"] == 'wa973tip2.txt'][\"content\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MUZIEKExtra show Like Mike & Dimi VegasHet eerste optreden van de dj's Like Mike & Dimitri Vegas in het Sportpaleis is uitverkocht , dus komt er een tweede show op 20 december . De kaartverkoop start op woensdag 23 oktober om 10 uur . De broers uit Willebroek dragen de show op aan hun overleden overgrootvader , René Mampaey , die mee aan de wieg van het Sportpaleis stond . De Facebook-pagina van de twee heeft ondertussen de kaap van twee miljoen fans gerond. ( bpr ) JeugdliteratuurBelgen kandidaat voor LindgrenprijsBij de 238 genomineerden voor de Astrid Lindgren Memorial Award 2014 zijn vijf Belgen : illustratoren Carll Cneut en Klaas Verplancke en schrijvers Bart Moeyaert , Anne Herbauts en Thomas Lavachery . Ook de Waalse literatuurprijs Prix Bernard Versele maakt kans . De Zweedse award beloont schrijvers en illustratoren die ' in de geest van Astrid Lindgren werken '. De winnaar strijkt een bedrag van 570.000 euro op. ( belga ) Film'Het vonnis ' start ijzersterkHet vonnis van Jan Verheyen heeft tot zondagavond 49.175 kijkers getrokken . Dat is een uitstekend resultaat , want publiekstrekkers als 2 Guns trekken nog steeds veel volk en vrijdag hield de concurrentie van de Rode Duivels de helft van het normale bioscooppubliek weg . Met de avant-premières heeft de film al 88.000 betalende bezoekers getrokken . De zaak Alzheimer , dat ook half oktober van start ging , startte met een vergelijkbare 49.399 bezoekers. ( isg ) \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stan_df.loc[stan_df[\"filename\"] == 'De_Standaard-2013-10-15(6).000001#3n.xml']['content'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "waContent_list = evaluationDf.WaContent.tolist()\n",
    "stanContent_list = evaluationDf.StanContent.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "waFile_list = []\n",
    "stanFile_list = []\n",
    "simscorewastan = []\n",
    "for i in range(0, len(waContent_list)):\n",
    "    wa_content = waContent_list[i]\n",
    "    stan_content = stanContent_list[i]\n",
    "    wa_filename = wa_df.loc[wa_df[\"content\"] == wa_content].filename.tolist()[0]\n",
    "    waFile_list.append(wa_filename)\n",
    "    stan_filename = stan_df.loc[stan_df[\"content\"] == stan_content].filename.tolist()[0]\n",
    "    stanFile_list.append(stan_filename)\n",
    "    try:\n",
    "        simscorewastan.append(simDict_Wastan[wa_filename][\"Score\"][simDict_Wastan[wa_filename]['Standaard'].index(stan_filename)])\n",
    "    except ValueError:\n",
    "        simscorewastan.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationDf['ScoreRobWaStan'] = simscorewastan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('manualRatedDfRobbWaStan.pickle', 'wb') as handle:\n",
    "    pickle.dump(evaluationDf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3456e290f23e66e65c86db29512030f5b9518fa8a585a84d9a5b83ccae9d6ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
